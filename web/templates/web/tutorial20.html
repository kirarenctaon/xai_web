{% extends "web/index.html" %} {% block content %} {% load static%}
<!-- static을 사용하는 모든 개별 html에서 별도로 호출해야함 -->
<section id="inner-headline">
<div class="container">
	<div class="row">
		<div class="col-lg-12">
			<ul class="breadcrumb">
				<li><a href="#"><i class="fa fa-home"></i></a><i class="icon-angle-right"></i></li>
				<li class="active">Tutorial</li>
			</ul>
		</div>
	</div>
</div>
</section>
<section id="content">
<div class="container">
	<div class="lead">
	<div class="row">
		<!--<ul class="nav nav-tabs">-->
			<!--<li class="active"><a href="#English" data-toggle="tab"><i class="icon-briefcase"></i> English</a></li>-->
			<!--<li><a  href ='{% url 'Symposium18_ko' %}' >한국어</a></li>-->
		<!--</ul>-->
		<div class="tab-content">
			<div class="tab-pane active" id="English">
				<div class="col-lg-12">
					<div class="post-image">
						<div class="post-heading">
							<a href="http://www.kdd.org/kdd2020/calls/view/kdd-2020-call-for-research-papers"><img src="/static/img/event/KDD2020-banner.gif" style=""/></a><br>
							<br>
							<h1>KDD2020 Tutorial on</h1>
							<h2>Interpreting and  Explaining Deep  Neural  Networks: A  Perspectiveon Time Series Data</h2>
							<br>
<!--							<h4>August 2020</h4>-->
							<h4>* Due to COVID-19, the tutorials will be delivered virtually this year.</h4>
							<br>
						</div>
						<div class="col-lg-12">
							<div class="row">
								<a href="#Introduction" class="btn btn-warning">Abstract</a>
<!--								<a href="#requirements" class="btn btn-warning">Detailed Descriptions </a>-->
								<a href="#Program" class="btn btn-theme">Program</a>
								<a href="#Tutors" class="btn btn-info">Tutors</a>
								<a href="#Reference" class="btn btn-success">Reference</a>
							</div>
						</div>
					</div>
					<!-- divider -->
					<div class="row">
						<div class="col-lg-12">
							<div class="solidline">
							</div>
						</div>
					</div>
					<!-- end divider -->
					<a href="#" class="btn btn-warning btn-large">Abstract</a>
					<br>
					<br>
					<article>
						Explainable and interpretable machine learning models and algorithms are important topics which
						have received growing attention from research, application and administration. Many advanced Deep
						Neural Networks (DNNs)are often perceived as black-boxes. Researchers would like to be able to
						interpret what the DNNhas learned in order to identify biases and failure models and improve models.
						In this tutorial, we will provide a comprehensive overview on methods to analyze deep neural networks
						and an insight how those XAI methods help us understand time series data.
					</article>
					<!-- divider -->
					<div class="row">
						<div class="col-lg-12">
							<div class="solidline">
							</div>
						</div>
					</div>
					<!-- end divider -->
					<!-- Descriptions -->
					<a href="#" class="btn btn-theme btn-large" id="Program">Program</a>
					<br>
					<br>
					<div class="row">
						<div class="alert alert-info">
						<strong> Overview of Interpreting Deep Neural Networks </strong>
						</div>
							&nbsp;&nbsp;&nbsp;At first, wewill provide a comprehensive to explain fundamental principles in interpreting and explaining deep neural networks. Thetopic of the talk may include relevance score based methods [Layer Relevance Propagation (LRP),
							Deep Taylor Decomposition (DTD), PatternNet, and RAP] and gradient based methods [DeConvNet, DeepLIFT, Guided Backprop].
							We will also present a new perspective by presenting methods on Meta-Explanations [CleverHans] and Neuralization methods [ClusterExplanations].</li>
							<br><br>
						<div class="alert alert-info">
						<strong> Interpreting Inside of Deep Neural Networks </strong>
						</div>
							&nbsp;&nbsp;&nbsp;In the last section, wewill present methods to interpreting internal nodes of deep neural networks. Jaesik will start the session by introducing method to visualizechannels of Convolutional Neural Networks [Network Dissection] and Generative Adversarial Networks [GAN Dissection].
	Then, he will present methods [Convex Hull, Cluster Explanations, E-GBAS]to analyze internal nodes of DNNs by analyzing a set of decision boundaries.When allowed, Jaesik will briefly overview the methods to explain DNNs by using attention methods.</li>
							<br><br>
						<div class="alert alert-info">
						<strong> Explaining Time Series Data </strong>
						</div>
							&nbsp;&nbsp;&nbsp;In the last section, we will introduce recent explainable methods on Time Series Domain. We will introduce [N-BEATS], a framework performing regression tasks and providing outputs that are interpretable without considerable loss in accuracy. [CPHAP] interprets the decision of temporal neural networks by extracting highly activated periods. Furthermore, this clustered results of this method provide an intuition of understanding data mining.
							Finally, we will present a method [Automatic Statistician] that predicts time series with a human-readable report, including the reason for prediction.
							<br><br>
							<div class="col-lg-12">
							<div class="pricing-box-alt special">
								<div class="pricing-heading">
								   <h3><strong>Tutorial outline</strong> </h3>
							    </div>
							 	<table  class="table table-bordered" style="text-align: center;">
									<thead>
									<tr style="color: white; background-color:#393a3d;">
										<th style="text-align: center;width:20%">
											Time
										</th>
										<th style="text-align: center;width:20%">
											Tutor
										</th>
										<th style="text-align: center;width:60%">
											Detail
										</th>
									</tr>
									</thead>
									<tr>
										<td>50 min</td>
										<th rowspan="3" style="text-align: center;font-weight: lighter;"> Jaesik Choi<br> (KAIST)</th>
										<td>Overview of InterpretingDeep Neural Networks</td>
									</tr>
									<tr>
										<td>50 min</td>
										<td>Interpreting Inside of Deep Neural Networks</td>
									</tr>
									<tr>
										<td>50 min</td>
										<td>Explaining TimeSeries Data</td>
									</tr>
								</table>
							</div>
							</div>
					<!-- divider -->
						<div class="row">
							<div class="col-lg-12">
								<div class="solidline">
								</div>
							</div>
						</div>
						<!-- end divider -->

					</div>
					<!-- divider -->
					<div class="row">
						<div class="col-lg-12">
							<div class="solidline">
							</div>
						</div>
					</div>
					<!-- end divider -->

					<!-- Descriptions -->
				<div class="row">
					<div class="col-lg-12">
					<a href="#" class="btn btn-primary btn-info" id="Tutors">Tutors</a>
					<br>
					<br>
					<div class="col-lg-12">
						<div style="text-align:center;">
							<img src={% static "img/member/jaesik_profile.jpg" %}><br>
						</div>
						<br>
						<span>&nbsp;&nbsp;&nbsp;<strong>Jaesik Choi</strong> is a director of the Explainable Artificial Intelligence Center of Koreasince 2017.
						He is an associate professor of Graduate School of Artificial Intelligenceat Korea Advanced Institute of Science and Technology (KAIST).
						He received his BS degree in computerscience and engineering at Seoul National University in 2004.
						He received his PhD degree in computer science at the University of Illinois at Urbana-Champaign in 2012</span>
						<br><br>
						<li>Email: <a href="mailto:jaesik.choi@kaist.ac.kr">jaesik.choi@kaist.ac.kr</a></li>
						<li>Homepage: <a href="http://sailab.kaist.ac.kr/jaesik">http://sailab.kaist.ac.kr/jaesik</a></li>
						<li>Affiliation: Korea Advanced Institute of Science and Technology (KAIST)</li>
						<li>Address: 8, Seongnam-daero 331,18F KINS Tower,Bundang, Seongnam, Gyeonggi, Republic of Korea</li>

						<br>

					</div>
					</div>
				</div>
					<!-- divider -->
					<div class="row">
						<div class="col-lg-12">
							<div class="solidline">
							</div>
						</div>
					</div>
					<!-- end divider -->
					<!-- Descriptions -->
					<div class="row">
					<div class="col-lg-12">
						<a href="#" class="btn btn-success btn-large" id="Reference">Reference</a>
						<br>
						<br>

						<div class="row">
							<div class="col-lg-12">
	1. <a href="https://www.darpa.mil/attachments/XAIProgramUpdate.pdf">Gunning, D. (2017). Explainable artificial intelligence (xai). Defense Advanced Research Projects Agency (DARPA).</a></br>
	2. <a href="https://robotics.sciencemag.org/content/robotics/4/37/eaay7120.full.pdf">Gunning, D., Stefik, D., Choi, J., Miller, T., Stumpf, S. and Yang G.-Z.(2019), XAI—Explainable artificial intelligence, Science Robotics, 4(37).</a></br>
	3. <a href="https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0130140&type=printable">[LRP] Bach, S., Binder, A., Montavon, G., Klauschen, F., Müller, K. R., & Samek, W. (2015). On pixel-wise explanationsfor non-linear classifier decisions by layer-wise relevance propagation. PloS one, 10(7), e0130140.</a></br>
	4. <a href="https://reader.elsevier.com/reader/sd/pii/S0031320316303582?token=F32A501C928B9386F04F247D1FDCBEE5B0448A857C05C6F6A817F321E352F689D0E9A6FB30659367A2C97940E10FE067">[DTD] Montavon, G., Lapuschkin, S., Binder, A., Samek, W., & Müller, K. R. (2017). Explaining nonlinear classification decisions with deep taylor decomposition. Pattern Recognition, 65, 211-222. </a></br>
	5. <a href="https://dl.acm.org/doi/pdf/10.1145/3206025.3206039">[PatternNet] Li, H., Ellis, J. G., Zhang, L., & Chang, S. F. (2018). Patternnet: Visual pattern mining with deep neural network. In Proceedings of the ACM on International Conference on Multimedia Retrieval (pp. 291-299).</a></br>
	6. <a href="https://www.nature.com/articles/s41467-019-08987-4.pdf">[Clever Hans] Lapuschkin, S., Wäldchen, S., Binder, A., Montavon, G., Samek, W., Muller, K.-R. (2019). Unmasking Clever Hans predictors and assessing what machines really learn. Nature Communication 10, 1096.</a><br>
	7. <a href="https://aaai.org/Papers/AAAI/2020GB/AAAI-NamWJ.5191.pdf">[RAP] Nam, W. J., Choi, J., & Lee, S. W. (2020). Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks. AAAI Conference on Artificial Intelligence. Gradient Based</a><br>
	8. <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-10590-1_53.pdf">[DeConvNet] Zeiler, Matthew D., and Rob Fergus. (2014). Visualizing and understanding convolutional networks. European conference on computer vision. Springer.</a><br>
	9. <a href="https://dl.acm.org/doi/pdf/10.5555/3305890.3306006">[DeepLIFT] Shrikumar, A., Greenside, P., & Kundaje, A. (2017). Learning important features through propagating activation differences. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp. 3145-3153). JMLR. org.</a><br>
	10. <a href="https://arxiv.org/pdf/1412.6806.pdf">[Guided Backprop] Springenberg, J. T., Dosovitskiy, A., Brox, T., & Riedmiller, M. (2014). Striving for simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806.</a><br>
	11. <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf">[GradCAM] Selvaraju, R. R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., & Batra, D. (2017). Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE International Conference on Computer Vision(pp. 618-626). Explaining Internal Nodes</a><br>
	12. <a href="https://arxiv.org/pdf/1704.05796.pdf">[Network Dissection] Bau, D., Zhou, B., Khosla, A., Oliva, A., & Torralba, A. (2017). Network dissection: Quantifying interpretability of deep visual representations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 6541-6549).</a><br>
	13. <a href="https://arxiv.org/pdf/1811.10597.pdf">[GAN Dissection] Bau, D., Zhu, J. Y., Strobelt, H., Zhou, B., Tenenbaum, J. B., Freeman, W. T., & Torralba, A. (2018). Gan dissection: Visualizing and understanding generative adversarial networks. arXiv preprint arXiv:1811.10597.</a><br>
	14. <a href="https://aaai.org/Papers/AAAI/2020GB/AAAI-JeonG.7148.pdf">[E-GBAS] Jeon, G., Jeong, H., Choi, J. (2020). An Efficient Explorative Sampling Considering the Generative Boundaries of Deep Generative Neural Networks. In Thirty-Third AAAI Conference on Artificial Intelligence.</a><br>
	15. <a href="https://arxiv.org/pdf/1906.07633.pdf">[Cluster Explanations] Kauffmann, J., Esders, M., Montavon, G., Samek, W., Muller, K.-R. (2019). From Clustering to Cluster Explanations via Neural Networks, Arxiv 1906.07633. Explaining though attention</a><br>
	16. <a href="https://papers.nips.cc/paper/6321-retain-an-interpretable-predictive-model-for-healthcare-using-reverse-time-attention-mechanism.pdf">[RETAIN] Choi, E., Bahadori, M. T., Sun, J., Kulas, J., Schuetz, A., & Stewart, W. (2016). Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. In Advances in Neural Information Processing Systems (pp. 3504-3512).</a><br>
	17. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zhao_Saliency_Detection_by_2015_CVPR_paper.pdf">[Saliency Maps] Zhao, R., Ouyang, W., Li, H., & Wang, X. (2015). Saliency detection by multicontext deep learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 1265-1274).</a><br>
	18. <a href="http://proceedings.mlr.press/v48/leeb16.pdf">[AMTL] Lee, G., Yang, E., & Hwang, S. (2016, June). Asymmetric multi-task learning based on task relatedness and loss. In International Conference on Machine Learning (pp. 230-238).</a><br>
	19. <a href="https://papers.nips.cc/paper/7370-uncertainty-aware-attention-for-reliable-interpretation-and-prediction.pdf">[UA] Heo, J., Lee, H. B., Kim, S., Lee, J., Kim, K. J., Yang, E., & Hwang, S. J. (2018). Uncertainty-aware attention for reliable interpretation and prediction. In Advances in Neural Information Processing Systems (pp. 909-918). Generating Explanations</a><br>
	20. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Andreas_Neural_Module_Networks_CVPR_2016_paper.pdf">[Neural Module Network] Andreas, J., Rohrbach, M., Darrell, T., & Klein, D. (2016). Neural module networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 39-48).</a><br>
	21. <a href="https://www.mpi-inf.mpg.de/fileadmin/inf/d2/akata/generating-visual-explanations.pdf">[GVE] Hendricks, L. A., Akata, Z., Rohrbach, M., Donahue, J., Schiele, B., & Darrell, T. (2016, October). Generating visual explanations. In European Conference on Computer Vision (pp. 3-19). Springer, Cham.</a><br>
	22. [10-K Reports] , Y. Chun at el, “Predicting and Explaining Cause of Changes in Stock Prices By Reading Annual Reports”, NeurIPS 2019 Workshop on Robust AI in Financial Services<br>
	23. <a href="https://doi.org/10.1016/j.neuroimage.2019.116113">[Regional Anomaly] Lee E., Choi J., Kim M., Suk H. (2019). Toward an interpretable Alzheimer's disease diagnostic model with regional abnormality representation via deep learning. In NeuroImage (vol. 202) Local Linear Explanation</a><br>
	24. <a href="https://dl.acm.org/doi/pdf/10.1145/2939672.2939778">[LIME] Ribeiro, M. T., Singh, S., & Guestrin, C. (2016, August). Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining (pp. 1135-1144). ACM.</a><br>
	25. <a href="https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf">[SHAP] Lundberg, S. M., & Lee, S. I. (2017). A unified approach to interpreting model predictions.In Advances in Neural Information Processing Systems (pp. 4765-4774). Decision Tree Explanator</a><br>
	26. <a href="https://arxiv.org/pdf/1905.10437.pdf">[N-BEATS] Oreshkin, Boris N., et al. N-BEATS: Neural basis expansion analysis for interpretable time series forecasting. arXiv preprint arXiv:1905.10437 (2019).</a><br>
	27. <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-030-05318-5_9.pdf">[Automatic Statistician] Steinruecken, C., Smith, E., Janz, D., Lloyd, J., & Ghahramani, Z. (2019). The Automatic Statistician. In Automated Machine Learning (pp. 161-173). Springer, Cham.</a><br>
	28. <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/viewFile/8240/8564">[ABCD] Lloyd, J. R., Duvenaud, D., Grosse, R., Tenenbaum, J., & Ghahramani, Z. (2014, June). Automatic construction and natural-language description of nonparametric regression models. In Twenty-eighth AAAI conference on artificial intelligence.</a><br>
	29. <a href="http://proceedings.mlr.press/v48/hwangb16.pdf">[R-ABCD] Hwang, Y., Tong, A., & Choi, J. (2016, June). Automatic construction of nonparametric relational regression models for multiple time series. In International Conference on Machine Learning(pp. 3030-3039)</a><br>
	30. <a href="http://xai.kaist.ac.kr/static/img/event/ICCV_2019_VXAI_Trevo_Talk.pdf">Trevor Darrell, “Recent progress towards XAI at UC Berkeley”, 2019 ICCV VXAI workshop http://xai.kaist.ac.kr/static/img/event/ICCV_2019_VXAI_Trevo_Talk.pdf</a><br>
	31. <a href="http://xai.kaist.ac.kr/static/img/event/ICCV_2019_VXAI_Samek_Talk.pdf">Wojciech Samek,“Meta-Explanations, Interpretable Clustering & Other Recent Development”, http://xai.kaist.ac.kr/static/img/event/ICCV_2019_VXAI_Samek_Talk.pdf</a><br>
							</div>
						</div>
						<div class="row">
							<div class="col-lg-12">
								<div class="solidline">
								</div>
							</div>
						</div>
						<!-- end divider -->
				</div>
			</div>
		</div>
	</div>
	</div>
</div>
</section>

<!-- divider -->
<div class="row">
	<div class="col-lg-12">
		<div class="solidline">
		</div>
	</div>
</div>
<!-- end divider -->
 {% endblock content %} {% block script %}
<script type="text/javascript" src="https://openapi.map.naver.com/openapi/v3/maps.js?clientId=g9DAE7AOMF4rEJUbJ0Kr"></script>
<script>
		// http://blog.goodkiss.co.kr/entry/ 좌표값 알아내는 사이트
		var mapOptions = {
		    center: new naver.maps.LatLng(37.5130620, 127.0586440),
		    zoom: 10
		};
		var map = new naver.maps.Map('naver-map', mapOptions);
		var marker = new naver.maps.Marker({position: new naver.maps.LatLng(37.5130620, 127.0586440), map:map})
	</script>
{% endblock script %}
